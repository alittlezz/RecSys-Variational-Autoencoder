{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCVAE",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPoOTkZVMzZj",
        "outputId": "7a02ee2c-6fd3-49c7-ce93-0f8512f16498"
      },
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "\n",
        "def RMSE(ratings_pred, ratings):\n",
        "    ratings_mask = ratings > 0\n",
        "    return torch.sum((ratings_pred * ratings_mask - ratings) ** 2)\n",
        "\n",
        "df_train = pd.read_csv('movielens100k_train.csv')\n",
        "df_test = pd.read_csv('movielens100k_test.csv')\n",
        "df_train['UserID'] = df_train['UserID'] - 1\n",
        "df_test['UserID'] = df_test['UserID'] - 1\n",
        "USERS = df_train['UserID'].max() + 1\n",
        "df_train['MovieID'] = df_train['MovieID'] - 1\n",
        "df_test['MovieID'] = df_test['MovieID'] - 1\n",
        "MOVIES = df_train['MovieID'].max() + 1\n",
        "df_train['Date'] = [datetime.utcfromtimestamp(x) for x in df_train['Timestamp']]\n",
        "df_test['Date'] = [datetime.utcfromtimestamp(x) for x in df_test['Timestamp']]\n",
        "\n",
        "MIN_DATE = min(df_train['Date'].min(), df_test['Date'].min())\n",
        "\n",
        "df_train['Days'] = [x.days for x in df_train['Date'] - MIN_DATE] \n",
        "df_test['Days'] = [x.days for x in df_test['Date'] - MIN_DATE]\n",
        "\n",
        "MIN_DAYS = min(df_train['Days'].min(), df_test['Days'].min())\n",
        "MAX_DAYS = max(df_train['Days'].max(), df_test['Days'].max())\n",
        "NO_DAY_BINS = 30\n",
        "BIN_SIZE = (MAX_DAYS + 1) / NO_DAY_BINS\n",
        "\n",
        "def get_day_bin(days):\n",
        "  return int(min(max(1, days // BIN_SIZE), NO_DAY_BINS) - 1)\n",
        "\n",
        "df = pd.concat([df_train, df_test])\n",
        "ROWS = df['UserID']\n",
        "COLS = df['MovieID']\n",
        "\n",
        "print('Finished feature engineering...')\n",
        "print('df shape', len(df))\n",
        "print('df_train.head()', len(df_train))\n",
        "print(df_train.head())\n",
        "print('df_test.head()', len(df_test))\n",
        "print(df_test.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished feature engineering...\n",
            "df shape 100000\n",
            "df_train.head() 80000\n",
            "   Unnamed: 0  UserID  MovieID  Rating  Timestamp                Date  Days\n",
            "0           0       0        0       5  874965758 1997-09-22 22:02:38     2\n",
            "1           1       0        1       3  876893171 1997-10-15 05:26:11    25\n",
            "2           2       0        2       4  878542960 1997-11-03 07:42:40    44\n",
            "3           3       0        3       3  876893119 1997-10-15 05:25:19    25\n",
            "4           4       0        4       3  889751712 1998-03-13 01:15:12   173\n",
            "df_test.head() 20000\n",
            "   Unnamed: 0  UserID  MovieID  Rating  Timestamp                Date  Days\n",
            "0           0       0        5       5  887431973 1998-02-14 04:52:53   147\n",
            "1           1       0        9       3  875693118 1997-10-01 08:05:18    11\n",
            "2           2       0       11       5  878542960 1997-11-03 07:42:40    44\n",
            "3           3       0       13       5  874965706 1997-09-22 22:01:46     2\n",
            "4           4       0       16       3  875073198 1997-09-24 03:53:18     4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DLhIPWCM7tN",
        "outputId": "c1bae469-6209-459b-fdc6-d69616a4bef9"
      },
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "seed = 1337\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device('cpu')\n",
        "print('Using device', device)\n",
        "torch.set_default_tensor_type(torch.FloatTensor)\n",
        "\n",
        "train_data = csr_matrix((df_train['Rating'], (df_train['UserID'], df_train['MovieID'])), shape=(USERS, MOVIES), dtype=np.float32)\n",
        "RMSE_train = torch.Tensor(train_data.copy().toarray()).to(device)\n",
        "rows, cols = train_data.nonzero()\n",
        "train_mn = train_data.min()\n",
        "train_mx = train_data.max()\n",
        "for i, j in zip(rows, cols):\n",
        "  train_data[i, j] = (train_data[i, j] - train_mn) / (train_mx - train_mn)\n",
        "\n",
        "\n",
        "test_data = csr_matrix((df_test['Rating'], (df_test['UserID'], df_test['MovieID'])), shape=(USERS, MOVIES), dtype=np.float32)\n",
        "RMSE_test = torch.Tensor(test_data.copy().toarray()).to(device)\n",
        "rows, cols = test_data.nonzero()\n",
        "test_mn = test_data.min()\n",
        "test_mx = test_data.max()\n",
        "for i, j in zip(rows, cols):\n",
        "  test_data[i, j] = (test_data[i, j] - test_mn) / (test_mx - test_mn)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using device cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3gmVid6OGeA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2c6ce05-9002-4646-af22-55bf298b811c"
      },
      "source": [
        "R_train = train_data\n",
        "R_train_tensor = []\n",
        "for i in range(USERS):\n",
        "    batch = R_train[i].nonzero()[1]\n",
        "    ts = torch.from_numpy(R_train[i, batch].todense().transpose().astype(np.float32)).to(device)\n",
        "    R_train_tensor.append(ts)\n",
        "print(len(R_train_tensor), R_train_tensor[0].shape)\n",
        "print(R_train.shape)\n",
        "\n",
        "R_train_T = train_data.transpose()\n",
        "R_train_tensor_T = []\n",
        "for j in range(MOVIES):\n",
        "    batch = R_train_T[j].nonzero()[1]\n",
        "    ts = torch.from_numpy(R_train_T[j, batch].todense().transpose().astype(np.float32)).to(device)\n",
        "    R_train_tensor_T.append(ts)\n",
        "print(len(R_train_tensor_T), R_train_tensor_T[0].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "943 torch.Size([135, 1])\n",
            "(943, 1682)\n",
            "1682 torch.Size([383, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA-s5UyLycii"
      },
      "source": [
        "import numpy as np\n",
        "from copy import deepcopy\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.distributions.multivariate_normal import MultivariateNormal\n",
        "from torch.autograd import Variable as V\n",
        "\n",
        "\n",
        "def swish(x):\n",
        "    return x.mul(torch.sigmoid(x))\n",
        "\n",
        "def log_norm_pdf(x, mu, logvar):\n",
        "    return -0.5*(logvar + np.log(2 * np.pi) + (x - mu).pow(2) / logvar.exp())\n",
        "\n",
        "def reparameterize(mu, logvar):\n",
        "  std = torch.exp(0.5*logvar)\n",
        "  eps = torch.randn_like(std)\n",
        "  return eps.mul(std).add_(mu)\n",
        "\n",
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        torch.nn.init.normal_(m.weight, 0, 0.0001)\n",
        "        torch.nn.init.constant_(m.bias, 0.001)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, hidden_dim, latent_dim, input_dim, eps=1e-1):\n",
        "        super(Encoder, self).__init__()\n",
        "        # self.fc1 = nn.Linear(input_dim, 40)\n",
        "        # self.ln1 = nn.LayerNorm(40, eps=eps)\n",
        "        # self.fc2 = nn.Linear(40, 20)\n",
        "        # self.ln2 = nn.LayerNorm(20, eps=eps)\n",
        "        # self.fc3 = nn.Linear(20, 10)\n",
        "        # self.ln3 = nn.LayerNorm(10, eps=eps)\n",
        "\n",
        "        # self.fc1 = nn.Linear(input_dim, 40)\n",
        "        # self.ln1 = nn.LayerNorm(40, eps=eps)\n",
        "        # self.fc2 = nn.Linear(40, 20)\n",
        "        # self.ln2 = nn.LayerNorm(20, eps=eps)\n",
        "        # self.fc3 = nn.Linear(20, 10)\n",
        "        # self.ln3 = nn.LayerNorm(10, eps=eps)\n",
        "\n",
        "        self.fc_mu = nn.Linear(input_dim, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(input_dim, latent_dim)\n",
        "\n",
        "        # self.fc1.apply(weights_init)\n",
        "        # self.fc2.apply(weights_init)\n",
        "        # self.fc3.apply(weights_init)\n",
        "        self.fc_mu.apply(weights_init)\n",
        "        self.fc_logvar.apply(weights_init)\n",
        "        \n",
        "    def forward(self, x, dropout_rate, calculate_loss=True):\n",
        "        # norm = x.pow(2).sum(dim=-1).sqrt()\n",
        "        # x = x / norm[:, None]\n",
        "\n",
        "        x = F.dropout(x, p=dropout_rate, training=self.training)\n",
        "        \n",
        "        # h1 = self.ln1(torch.relu(self.fc1(x)))\n",
        "        # h2 = self.ln2(torch.relu(self.fc2(h1)))\n",
        "        # h3 = self.ln3(torch.relu(self.fc3(h2)))\n",
        "        \n",
        "        mu, logvar = self.fc_mu(x), self.fc_logvar(x)\n",
        "\n",
        "        return mu, logvar\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_dim, latent_dim, input_dim, eps=1e-1):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        # self.fc1 = nn.Linear(latent_dim, 10)\n",
        "        # self.fc2 = nn.Linear(10, 20)\n",
        "        # self.fc3 = nn.Linear(20, 40)\n",
        "        self.fc4 = nn.Linear(latent_dim, input_dim)\n",
        "\n",
        "        # self.fc1.apply(weights_init)\n",
        "        # self.fc2.apply(weights_init)\n",
        "        # self.fc3.apply(weights_init)\n",
        "        self.fc4.apply(weights_init)\n",
        "\n",
        "    def forward(self, z, calculate_loss=True):\n",
        "        # h1 = torch.relu(self.fc1(z))\n",
        "        # h2 = torch.relu(self.fc2(h1))\n",
        "        # h3 = torch.relu(self.fc3(h2))\n",
        "        x = torch.sigmoid(self.fc4(z))\n",
        "\n",
        "        return x\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, hidden_dim, latent_dim, input_dim):\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        self.encoder = Encoder(hidden_dim, latent_dim, input_dim)\n",
        "        self.decoder = Decoder(hidden_dim, latent_dim, input_dim)\n",
        "        self.zr = torch.zeros(1, latent_dim).to(device=device)\n",
        "        self.mones = torch.ones(1, latent_dim).to(device) * -1\n",
        "\n",
        "\n",
        "    def forward(self, user_ratings, alpha=0.5, beta=None, gamma=1, dropout_rate=0.5, calculate_loss=True, n_epoch=1):\n",
        "        mu, logvar = self.encoder(user_ratings, dropout_rate=dropout_rate, calculate_loss=calculate_loss)    \n",
        "        z = reparameterize(mu, logvar)\n",
        "        x_pred = self.decoder(z, calculate_loss=calculate_loss)\n",
        "        \n",
        "        if calculate_loss:\n",
        "            if gamma:\n",
        "                kl_weight = gamma * 10\n",
        "            elif beta:\n",
        "                kl_weight = beta\n",
        "\n",
        "            user_mask = user_ratings > 0\n",
        "            mll = torch.pow(x_pred * user_mask - user_ratings, 2).sum(dim=-1).mul(kl_weight).mean()\n",
        "            # mll = (-torch.log(x_pred) * user_ratings).sum(dim=-1).mul(kl_weight).mean()\n",
        "            # prior = log_norm_pdf(z, self.zr, self.zr)\n",
        "            kld = (log_norm_pdf(z, mu, logvar)).sum(dim=-1).mul(kl_weight).mean()\n",
        "            negative_elbo = mll + kld\n",
        "            \n",
        "            return mu, negative_elbo\n",
        "        else:\n",
        "            return mu\n",
        "\n",
        "\n",
        "class DualVAE(nn.Module):\n",
        "    def __init__(self, hidden_dim, latent_dim, input_dim_users, input_dim_movies, eps=1e-1):\n",
        "        super(DualVAE, self).__init__()\n",
        "        self.movies_VAE = VAE(hidden_dim, latent_dim, input_dim_users)\n",
        "        self.users_VAE = VAE(hidden_dim, latent_dim, input_dim_movies)\n",
        "\n",
        "    def forward(self, ratings, beta=None, gamma=1, dropout_rate=0.5, calculate_loss=True, n_epoch=1):\n",
        "        if calculate_loss:\n",
        "          mu_users, user_loss = self.users_VAE(ratings, beta=beta, gamma=gamma, dropout_rate=dropout_rate, calculate_loss=calculate_loss, n_epoch=n_epoch)\n",
        "          mu_movies, movie_loss = self.movies_VAE(ratings.T, beta=beta, gamma=gamma, dropout_rate=dropout_rate, calculate_loss=calculate_loss, n_epoch=n_epoch)\n",
        "          y_hat = mu_users @ mu_movies.T\n",
        "\n",
        "          ratings_mask = ratings > 0\n",
        "          mse = torch.pow(y_hat * ratings_mask - ratings, 2).mean()\n",
        "          # normalizer = 0.5 * self.lambda_u * torch.sum(self.u_dev * torch.pow(self.U - z_i, 2).unsqueeze(2)) + 0.5 * self.lambda_v * torch.sum(self.v_dev * torch.pow(self.V - z_j, 2).unsqueeze(2))\n",
        "          total_loss = user_loss + movie_loss + mse\n",
        "          return total_loss, user_loss, movie_loss, mse\n",
        "        \n",
        "        mu_users = self.users_VAE(ratings, beta=beta, gamma=gamma, dropout_rate=dropout_rate, calculate_loss=calculate_loss, n_epoch=n_epoch)\n",
        "        mu_movies = self.movies_VAE(ratings.T, beta=beta, gamma=gamma, dropout_rate=dropout_rate, calculate_loss=calculate_loss, n_epoch=n_epoch)\n",
        "        y_hat = mu_users @ mu_movies.T\n",
        "\n",
        "        return y_hat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 777
        },
        "id": "WcELyxrhy0Nj",
        "outputId": "f7b06f9f-9112-49ff-9904-cea201b3591d"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import optim\n",
        "\n",
        "import random\n",
        "from copy import deepcopy\n",
        "from tqdm import trange\n",
        "\n",
        "args = {\n",
        "    'dataset': '',\n",
        "    'hidden_dim': 40,\n",
        "    'latent_dim': 5,\n",
        "    'batch_size': train_data.count_nonzero(),\n",
        "    'beta': None,\n",
        "    'gamma': 1,\n",
        "    'lr': 1e-6,\n",
        "    'n_epochs': 50000,\n",
        "    'dropout_rate': 0.5,\n",
        "    'print_step': 100,\n",
        "    'n_enc_epochs': 3,\n",
        "    'n_dec_epochs': 1,\n",
        "    'not_alternating': True,\n",
        "}\n",
        "\n",
        "user_losses = []\n",
        "movie_losses = []\n",
        "mse_losses = []\n",
        "\n",
        "\n",
        "def generate(batch_size, device, data_in, data_out=None, shuffle=False, samples_perc_per_epoch=1):\n",
        "    yield Batch(device, [], data_in, data_out)\n",
        "\n",
        "\n",
        "class Batch:\n",
        "    def __init__(self, device, idx, data_in, data_out=None):\n",
        "        self._device = device\n",
        "        self._idx = idx\n",
        "        self._data_in = data_in\n",
        "        self._data_out = data_out\n",
        "        \n",
        "    def get_ratings(self, is_out=False):\n",
        "        data = self._data_in\n",
        "        return data\n",
        "    \n",
        "    def get_ratings_to_dev(self, is_out=False):\n",
        "        ratings = self.get_ratings(is_out)\n",
        "        return torch.Tensor(ratings.toarray()).to(self._device)\n",
        "\n",
        "\n",
        "def evaluate(model, data_in, data_out, RMSE_data, metrics, data_mn, data_mx, samples_perc_per_epoch=1, batch_size=500):\n",
        "    metrics = deepcopy(metrics)\n",
        "    model.eval()\n",
        "    \n",
        "    for m in metrics:\n",
        "        m['score'] = []\n",
        "    \n",
        "    for batch in generate(batch_size=batch_size,\n",
        "                          device=device,\n",
        "                          data_in=data_in,\n",
        "                          data_out=data_out,\n",
        "                          samples_perc_per_epoch=samples_perc_per_epoch\n",
        "                         ):\n",
        "        \n",
        "        ratings = batch.get_ratings_to_dev()\n",
        "        ratings_pred = model(ratings, calculate_loss=False) * (data_mx - data_mn) + data_mn\n",
        "        for m in metrics:\n",
        "            x = m['metric'](ratings_pred, RMSE_data)\n",
        "            m['score'].append(x.cpu().detach())\n",
        "    for m in metrics:\n",
        "        m['score'] = np.sqrt(np.sum(m['score']) / data_in.count_nonzero())\n",
        "        \n",
        "    return [x['score'] for x in metrics]\n",
        "\n",
        "\n",
        "def run(model, opts, train_data, batch_size, n_epoch, n_epochs, beta, gamma, dropout_rate):\n",
        "    model.train()\n",
        "    for epoch in range(n_epochs):\n",
        "        for batch in generate(batch_size=batch_size, device=device, data_in=train_data, shuffle=False):\n",
        "            ratings = batch.get_ratings_to_dev()\n",
        "\n",
        "            for optimizer in opts:\n",
        "                optimizer.zero_grad()\n",
        "              \n",
        "            loss, user_loss, movie_loss, mse = model(ratings, beta=beta, gamma=gamma, dropout_rate=dropout_rate, n_epoch=n_epoch)\n",
        "            loss.backward()\n",
        "\n",
        "            user_losses.append(user_loss)\n",
        "            movie_losses.append(movie_loss)\n",
        "            mse_losses.append(mse)\n",
        "\n",
        "            for optimizer in opts:\n",
        "                optimizer.step()\n",
        "\n",
        "\n",
        "model_kwargs = {\n",
        "    'hidden_dim': args['hidden_dim'],\n",
        "    'latent_dim': args['latent_dim'],\n",
        "    'input_dim_users': train_data.shape[0],\n",
        "    'input_dim_movies': train_data.shape[1]\n",
        "}\n",
        "metrics = [{'metric': RMSE}]\n",
        "\n",
        "best_ndcg = -np.inf\n",
        "train_scores, valid_scores = [], []\n",
        "\n",
        "model = DualVAE(**model_kwargs).to(device)\n",
        "batch = Batch(device, [], train_data, train_data)\n",
        "ratings = batch.get_ratings_to_dev()\n",
        "model_best = DualVAE(**model_kwargs).to(device)\n",
        "\n",
        "learning_kwargs = {\n",
        "    'model': model,\n",
        "    'train_data': train_data,\n",
        "    'batch_size': args['batch_size'],\n",
        "    'beta': args['beta'],\n",
        "    'gamma': args['gamma']\n",
        "}\n",
        "\n",
        "optimizer = optim.Adam(set(model.parameters()), lr=args['lr'], weight_decay=1)\n",
        "import time\n",
        "for epoch in range(args['n_epochs']):\n",
        "    if epoch % args['print_step'] == 0:\n",
        "        t = time.time()\n",
        "\n",
        "    run(opts=[optimizer], n_epoch=epoch, n_epochs=1, dropout_rate=args['dropout_rate'], **learning_kwargs)\n",
        "\n",
        "    train_scores.append(\n",
        "        evaluate(model, train_data, train_data, RMSE_train, metrics, train_mn, train_mx, 1, batch_size=args['batch_size'])[0]\n",
        "    )\n",
        "    valid_scores.append(\n",
        "        evaluate(model, test_data, test_data, RMSE_test, metrics, test_mn, test_mx, 1, batch_size=args['batch_size'])[0]\n",
        "    )\n",
        "    if epoch % args['print_step'] == 0:\n",
        "      print('Epoch:', epoch, 'train_RMSE=', f'{train_scores[-1]:.4f}', 'test_RMSE', f'{valid_scores[-1]:.4f}')\n",
        "      print('Time:', time.time() - t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 train_RMSE= 3.7014 test_RMSE 3.7193\n",
            "Time: 0.2701749801635742\n",
            "Epoch: 100 train_RMSE= 3.7010 test_RMSE 3.7192\n",
            "Time: 0.014446735382080078\n",
            "Epoch: 200 train_RMSE= 3.6955 test_RMSE 3.7185\n",
            "Time: 0.01509857177734375\n",
            "Epoch: 300 train_RMSE= 3.6769 test_RMSE 3.7160\n",
            "Time: 0.014678716659545898\n",
            "Epoch: 400 train_RMSE= 3.6365 test_RMSE 3.7106\n",
            "Time: 0.014102697372436523\n",
            "Epoch: 500 train_RMSE= 3.5740 test_RMSE 3.7021\n",
            "Time: 0.014379501342773438\n",
            "Epoch: 600 train_RMSE= 3.4926 test_RMSE 3.6907\n",
            "Time: 0.014168977737426758\n",
            "Epoch: 700 train_RMSE= 3.3964 test_RMSE 3.6768\n",
            "Time: 0.014819622039794922\n",
            "Epoch: 800 train_RMSE= 3.2897 test_RMSE 3.6607\n",
            "Time: 0.014062881469726562\n",
            "Epoch: 900 train_RMSE= 3.1766 test_RMSE 3.6426\n",
            "Time: 0.014884233474731445\n",
            "Epoch: 1000 train_RMSE= 3.0616 test_RMSE 3.6229\n",
            "Time: 0.014086723327636719\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-0e3a8b7cb7d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    157\u001b[0m     )\n\u001b[1;32m    158\u001b[0m     valid_scores.append(\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRMSE_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'print_step'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-0e3a8b7cb7d5>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, data_in, data_out, RMSE_data, metrics, data_mn, data_mx, samples_perc_per_epoch, batch_size)\u001b[0m\n\u001b[1;32m     78\u001b[0m                          ):\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ratings_to_dev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mratings_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalculate_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdata_mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# ratings_pred = ratings_pred + R_prec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-0e3a8b7cb7d5>\u001b[0m in \u001b[0;36mget_ratings_to_dev\u001b[0;34m(self, is_out)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_ratings_to_dev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ratings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}