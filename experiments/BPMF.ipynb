{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrtOo0UsnHBU",
        "outputId": "9d3921ec-2dc6-43ce-8028-f0cea479ed66"
      },
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "df_train = pd.read_csv('douban_train.csv')\n",
        "df_test = pd.read_csv('douban_test.csv')\n",
        "\n",
        "df_train['UserID'] = df_train['UserID']\n",
        "df_test['UserID'] = df_test['UserID']\n",
        "USERS = max(df_train['UserID'].max(), df_test['UserID'].max()) + 1\n",
        "df_train['MovieID'] = df_train['MovieID']\n",
        "df_test['MovieID'] = df_test['MovieID']\n",
        "MOVIES = max(df_train['MovieID'].max(), df_test['MovieID'].max()) + 1\n",
        "\n",
        "print(USERS, MOVIES, df_train['MovieID'].max(), df_test['MovieID'].max())\n",
        "\n",
        "df = pd.concat([df_train, df_test])\n",
        "ROWS = df['UserID']\n",
        "COLS = df['MovieID']\n",
        "\n",
        "print('Finished feature engineering...')\n",
        "print('df shape', len(df))\n",
        "print('df_train.head()', len(df_train))\n",
        "print(df_train.head())\n",
        "print('df_test.head()', len(df_test))\n",
        "print(df_test.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11777 20697 20696 20681\n",
            "Finished feature engineering...\n",
            "df shape 190590\n",
            "df_train.head() 152528\n",
            "   Unnamed: 0  Unnamed: 0.1  UserID  MovieID  Rating\n",
            "0           0             0       0        0       5\n",
            "1           2             2       0        2       5\n",
            "2           3             3       0        3       4\n",
            "3           4             4       0        4       4\n",
            "4           5             5       0        5       4\n",
            "df_test.head() 38062\n",
            "   Unnamed: 0  Unnamed: 0.1  UserID  MovieID  Rating\n",
            "0           1             1       0        1       5\n",
            "1          12            12       1       12       3\n",
            "2          21            21       2       21       5\n",
            "3          23            23       3       23       5\n",
            "4          25            25       3       25       5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v2IM_WPOuk-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21edc404-7d11-436e-e8a0-393aa56eb0c2"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import trange\n",
        "from scipy.sparse import csr_matrix\n",
        "import torch\n",
        "import random\n",
        "\n",
        "seed = 1337\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "\n",
        "# device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device('cpu')\n",
        "device = torch.device('cpu')\n",
        "torch.set_default_tensor_type(torch.FloatTensor)\n",
        "\n",
        "T = len(df_test)\n",
        "T_train = len(df_train)\n",
        "\n",
        "df_test_2 = df_test.copy()\n",
        "df_test_2['Rating'] = -1\n",
        "\n",
        "df_train_2 = df_train.copy()\n",
        "df_train_2['Rating'] = -1\n",
        "\n",
        "rating_matrix = pd.concat([df_train, df_test_2]).pivot(index='UserID', columns='MovieID', values='Rating')\n",
        "rating_matrix[rating_matrix.isna()] = -1\n",
        "rating_matrix = torch.from_numpy(rating_matrix.values).to(device)\n",
        "non_zero_mask = (rating_matrix != -1)\n",
        "print(rating_matrix.shape)\n",
        "USERS,MOVIES = rating_matrix.shape\n",
        "\n",
        "test_matrix = pd.concat([df_test, df_train_2]).pivot(index='UserID', columns='MovieID', values='Rating')\n",
        "test_matrix[test_matrix.isna()] = -1\n",
        "test_matrix = torch.from_numpy(test_matrix.values).to(device)\n",
        "non_zero_mask_test = (test_matrix != -1)\n",
        "print(test_matrix.device)\n",
        "\n",
        "R_train = csr_matrix((df_train['Rating'], (df_train['UserID'], df_train['MovieID'])), shape=(USERS, MOVIES), dtype=np.float)\n",
        "\n",
        "R_train_tensor = []\n",
        "for i in range(USERS):\n",
        "    batch = R_train[i].nonzero()[1]\n",
        "    ts = torch.from_numpy(R_train[i, batch].todense().transpose().astype(np.float32)).to(device)\n",
        "    R_train_tensor.append(ts)\n",
        "print(len(R_train_tensor), R_train_tensor[0].shape)\n",
        "print(R_train.shape)\n",
        "\n",
        "R_train_T = R_train.transpose()\n",
        "R_train_tensor_T = []\n",
        "for j in range(MOVIES):\n",
        "    batch = R_train_T[j].nonzero()[1]\n",
        "    ts = torch.from_numpy(R_train_T[j, batch].todense().transpose().astype(np.float32)).to(device)\n",
        "    R_train_tensor_T.append(ts)\n",
        "print(len(R_train_tensor_T), R_train_tensor_T[0].shape)\n",
        "R_test = csr_matrix((df_test['Rating'], (df_test['UserID'], df_test['MovieID'])), shape=(USERS, MOVIES))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([11777, 20697])\n",
            "cpu\n",
            "11777 torch.Size([7, 1])\n",
            "(11777, 20697)\n",
            "20697 torch.Size([108, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fF8fbKNWn9Bl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b71068a-6005-46db-bc6c-8395b179e560"
      },
      "source": [
        "import time\n",
        "from scipy.stats import multivariate_normal, wishart\n",
        "import tensorflow as tf\n",
        "\n",
        "f = 10\n",
        "num_epochs = 10\n",
        "\n",
        "T = len(df_test)\n",
        "T_train = len(df_train)\n",
        "U_history = []\n",
        "V_history = []\n",
        "U = torch.normal(mean=0., std=0.1, size=(USERS, f))\n",
        "U_sm175 = torch.zeros(size=(USERS, f))\n",
        "V_sm175 = torch.zeros(size=(MOVIES, f))\n",
        "\n",
        "U_sm200 = torch.zeros(size=(USERS, f))\n",
        "V_sm200 = torch.zeros(size=(MOVIES, f))\n",
        "\n",
        "U_sm225 = torch.zeros(size=(USERS, f))\n",
        "V_sm225 = torch.zeros(size=(MOVIES, f))\n",
        "\n",
        "V = torch.normal(mean=0., std=0.1, size=(MOVIES, f))\n",
        "R_hat_sm = torch.zeros((USERS, MOVIES))\n",
        "\n",
        "alpha = 1\n",
        "\n",
        "v_0 = f\n",
        "v_users = v_0 + USERS\n",
        "v_movies = v_0 + MOVIES\n",
        "W_0 = torch.eye(f)\n",
        "\n",
        "mean_0 = torch.zeros((f))\n",
        "beta_0 = 1\n",
        "beta_users = beta_0 + USERS\n",
        "beta_movies = beta_0 + MOVIES\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    t = time.time()\n",
        "    u_conv_all = torch.stack([torch.einsum('n,m->nm', ui, ui.T) for ui in U])\n",
        "    v_conv_all = torch.stack([torch.einsum('n,m->nm', vj, vj.T) for vj in V])\n",
        "    # Compute users variables\n",
        "\n",
        "    U_mean = torch.mean(U, axis=0, keepdims=True)\n",
        "    S_U = torch.mean(u_conv_all, axis=0)\n",
        "\n",
        "    W_users = torch.inverse(W_0 + USERS * S_U + beta_0 * USERS / (beta_0 + USERS) * (mean_0 - U_mean).T @ (mean_0 - U_mean))\n",
        "    mean_0_star = torch.squeeze(((beta_0 * mean_0 + USERS * U_mean) / (beta_0 + USERS))).to(dtype=torch.float64)\n",
        "\n",
        "    # Sample user precision and mean\n",
        "\n",
        "\n",
        "    precision_u = torch.from_numpy(wishart.rvs(v_users, scale=W_users))\n",
        "    # print((beta_users * covariance_u).dtype)\n",
        "    # print(mean_0_star.dtype)\n",
        "    # mean_u = torch.from_numpy(multivariate_normal.rvs(mean_0_star, cov=torch.inverse(beta_users * covariance_u))).reshape((1, f))\n",
        "    mean_u = torch.unsqueeze(torch.distributions.MultivariateNormal(loc=mean_0_star, precision_matrix=beta_users * precision_u).sample(), 0)\n",
        "\n",
        "\n",
        "    # Sample user feature matrix\n",
        "    for i in range(USERS):\n",
        "      batch = torch.from_numpy(R_train[i].nonzero()[1]).to(dtype=torch.int64)\n",
        "      v_sum = torch.sum(v_conv_all[batch], axis=0)\n",
        "      v_conv = torch.sum(R_train_tensor[i] * V[batch], axis=0)      \n",
        "      \n",
        "      precision_i = precision_u + alpha * v_sum\n",
        "      covariance_i = torch.inverse(precision_i)\n",
        "      mean_i = torch.squeeze(((alpha * v_conv + mean_u @ precision_u) @ covariance_i))\n",
        "      # U[i] = torch.from_numpy(multivariate_normal.rvs(mean_i, cov=inv_covariance_i))\n",
        "      U[i] = torch.distributions.MultivariateNormal(mean_i, covariance_i).sample()\n",
        "    # Compute movies variables\n",
        "\n",
        "    V_mean = torch.mean(V, axis=0, keepdims=True)\n",
        "    S_V = torch.mean(v_conv_all, axis=0)\n",
        "    \n",
        "    W_movies = torch.inverse(W_0 + MOVIES * S_V + beta_0 * MOVIES / (beta_0 + MOVIES) * (mean_0 - V_mean).T @ (mean_0 - V_mean))\n",
        "    mean_0_star = torch.squeeze(((beta_0 * mean_0 + MOVIES * V_mean) / (beta_0 + MOVIES))).to(dtype=torch.float64)\n",
        "    \n",
        "    # Sample movie covariance and mean\n",
        "\n",
        "    precision_v = torch.from_numpy(wishart.rvs(v_movies, scale=W_movies))\n",
        "    # mean_v = torch.from_numpy(multivariate_normal.rvs(mean_0_star, cov=torch.inverse(beta_movies * covariance_v))).reshape((1, f))\n",
        "    mean_v = torch.unsqueeze(torch.distributions.MultivariateNormal(loc=mean_0_star, precision_matrix=beta_movies * precision_v).sample(), 0)\n",
        "\n",
        "    u_conv_all = torch.stack([torch.einsum('n,m->nm', ui, ui.T) for ui in U])\n",
        "    \n",
        "    # Sample movie feature matrix\n",
        "\n",
        "    for j in range(MOVIES):\n",
        "      batch = torch.from_numpy(R_train_T[j].nonzero()[1]).to(dtype=torch.int64)\n",
        "      u_sum = torch.sum(u_conv_all[batch], axis=0)\n",
        "      u_conv = torch.sum(R_train_tensor_T[j] * U[batch], axis=0)\n",
        "\n",
        "      precision_j = precision_v + alpha * u_sum\n",
        "      covariance_j = torch.inverse(precision_j)\n",
        "      mean_j = torch.squeeze(((alpha * u_conv + mean_v @ precision_v) @ covariance_j))\n",
        "\n",
        "      V[j] = torch.distributions.MultivariateNormal(mean_j, covariance_j).sample()\n",
        "      # V[j] = torch.from_numpy(multivariate_normal.rvs(mean_j, cov=inv_covariance_j))\n",
        "\n",
        "\n",
        "    # R_hat = U @ V.T\n",
        "    if t > 175:\n",
        "      U_sm175 = U_sm175 + U\n",
        "      V_sm175 = V_sm175 + V\n",
        "    \n",
        "    if t > 200:\n",
        "      U_sm200 = U_sm200 + U\n",
        "      V_sm200 = V_sm200 + V\n",
        "\n",
        "    if t > 225:\n",
        "      U_sm225 = U_sm225 + U\n",
        "      V_sm225 = V_sm225 + V\n",
        "    print('Epoch', epoch, time.time() - t)\n",
        "\n",
        "torch.save(U_sm175, 'U175.pt')\n",
        "torch.save(V_sm175, 'V175.pt')\n",
        "torch.save(U_sm200, 'U200.pt')\n",
        "torch.save(V_sm200, 'V200.pt')\n",
        "torch.save(U_sm225, 'U225.pt')\n",
        "torch.save(V_sm225, 'V225.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 42.57160186767578\n",
            "Epoch 1 42.52551031112671\n",
            "Epoch 2 42.29231405258179\n",
            "Epoch 3 41.80431938171387\n",
            "Epoch 4 42.72337794303894\n",
            "Epoch 5 43.36680746078491\n",
            "Epoch 6 42.1110737323761\n",
            "Epoch 7 41.75307273864746\n",
            "Epoch 8 42.25348901748657\n",
            "Epoch 9 42.37766981124878\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}